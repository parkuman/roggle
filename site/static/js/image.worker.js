/* eslint-disable no-undef */
/**
 * This file is a Web Worker Responsible for loading and
 * running OpenCV commands off the main thread
 */

const paths = {
	openCvWasm: "./opencv/wasm/opencv.js",
	openCvThreads: "./opencv/threads/opencv.js",
	openCvSimd: "./opencv/wasm/opencv.js", // TODO: use SIMD
	openCvThreadsSimd: "./opencv/threads_simd/opencv.js",
	openCvWasmFeatureDetect: "./opencv/wasm-feature-detect.js",
	tfjs: "./tensorflow/tfjs.min.js",
	tfjsWasmBackend: "./tensorflow/tfjs-backend-wasm.min.js",
	tfjsWasm: "./tensorflow/tfjs-backend-wasm.wasm",
	tfjsWasmSimd: "./tensorflow/tfjs-backend-wasm-simd.wasm",
	tfjsWasmThreadedSimd: "./tensorflow/tfjs-backend-wasm-threaded-simd.wasm"
};

/**
 *  This is the code mostly generated by OpenCV for loading depending on what
 *  wasm features are enabled in the browser, just moved to a function inside here.
 *
 * @returns the path to the correct opencv script to use depending on the current browser's features
 *
 * 					simd - single instruction multiple data
 * 					multithreading - multithreading using WASM
 * 					simd + threads - browser supports both for WebAssembly
 */
async function getOpenCV() {
	let OPENCV_URL = "";
	let wasmPath = "";
	let simdPath = "";
	let threadsPath = "";
	let threadsSimdPath = "";

	if ("openCvWasm" in paths) {
		wasmPath = paths["openCvWasm"];
	}

	if ("openCvThreads" in paths) {
		threadsPath = paths["openCvThreads"];
	}

	if ("openCvSimd" in paths) {
		simdPath = paths["openCvSimd"];
	}

	if ("openCvThreadsSimd" in paths) {
		threadsSimdPath = paths["openCvThreadsSimd"];
	}

	let wasmSupported = !(typeof WebAssembly === "undefined");
	if (!wasmSupported) {
		throw new Error("The browser doesn't support WebAssembly, cannot load OpenCV");
	}

	let simdSupported = wasmSupported ? await wasmFeatureDetect.simd() : false;
	let threadsSupported = wasmSupported ? await wasmFeatureDetect.threads() : false;

	if (simdSupported && threadsSupported && threadsSimdPath != "") {
		OPENCV_URL = threadsSimdPath;
		console.log("Loading OpenCV.js with simd and threads optimization");
	} else if (simdSupported && simdPath != "") {
		if (threadsSupported && threadsSimdPath === "") {
			console.log(
				"The browser supports simd and threads, but the path of OpenCV.js with simd and threads optimization is empty"
			);
		}
		OPENCV_URL = simdPath;
		console.log("Loading OpenCV.js with simd optimization");
	} else if (threadsSupported && threadsPath != "") {
		if (simdSupported && threadsSimdPath === "") {
			console.log(
				"The browser supports simd and threads, but the path of OpenCV.js with simd and threads optimization is empty"
			);
		}
		OPENCV_URL = threadsPath;
		console.log("Loading OpenCV.js with threads optimization");
	} else if (wasmSupported && wasmPath != "") {
		if (simdSupported && threadsSupported) {
			console.log(
				"The browser supports simd and threads, but the path of OpenCV.js with simd and threads optimization is empty"
			);
		}

		if (simdSupported) {
			console.log(
				"The browser supports simd optimization, but the path of OpenCV.js with simd optimization is empty"
			);
		}

		if (threadsSupported) {
			console.log(
				"The browser supports threads optimization, but the path of OpenCV.js with threads optimization is empty"
			);
		}

		OPENCV_URL = wasmPath;
		console.log("Loading OpenCV.js for wasm");
	} else if (wasmSupported) {
		console.log("The browser supports wasm, but the path of OpenCV.js for wasm is empty");
	}

	if (OPENCV_URL === "") {
		throw new Error("No available OpenCV.js, please check your paths");
	}

	return OPENCV_URL;
}

const EPSILON = 30;
function imageProcessing({ msg, data }) {
	const img = cv.matFromImageData(data);

	// convert image to grayscale and adaptively threshold to hopefully show lines separating objects
	cv.cvtColor(img, img, cv.COLOR_BGR2GRAY);
	cv.adaptiveThreshold(img, img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 33, 40);

	// const contours = new cv.MatVector();
	// const hierarchy = new cv.Mat();
	// const poly = new cv.MatVector();
	// const contourImgBuffer = cv.Mat.zeros(img.rows, img.cols, cv.CV_8UC3);

	// // find all contours in the image and approximate them
	// cv.findContours(img, contours, hierarchy, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE);
	// for (let i = 0; i < contours.size(); ++i) {
	// 	let approximatedContour = new cv.Mat();
	// 	let cnt = contours.get(i);
	// 	// You can try more different parameters
	// 	cv.approxPolyDP(cnt, approximatedContour, EPSILON, true);
	// 	poly.push_back(approximatedContour);

	// 	cnt.delete();
	// 	approximatedContour.delete();
	// }

	// // draw contours with random Scalar
	// for (let i = 0; i < contours.size(); ++i) {
	// 	let color = new cv.Scalar(
	// 		Math.round(Math.random() * 255),
	// 		Math.round(Math.random() * 255),
	// 		Math.round(Math.random() * 255)
	// 	);
	// 	cv.drawContours(contourImgBuffer, poly, i, color, 1, 8, hierarchy, 0);
	// }

	postMessage({ msg, payload: imageDataFromMat(img) });

	// cleanup
	contourImgBuffer.delete();
	img.delete();
	poly.delete();
	contours.delete();
	hierarchy.delete();
}

/**
 * This function converts again from cv.Mat to ImageData
 */
function imageDataFromMat(mat) {
	// converts the mat type to cv.CV_8U
	const img = new cv.Mat();
	const depth = mat.type() % 8;
	const scale = depth <= cv.CV_8S ? 1.0 : depth <= cv.CV_32S ? 1.0 / 256.0 : 255.0;
	const shift = depth === cv.CV_8S || depth === cv.CV_16S ? 128.0 : 0.0;
	mat.convertTo(img, cv.CV_8U, scale, shift);

	// converts the img type to cv.CV_8UC4
	switch (img.type()) {
		case cv.CV_8UC1:
			cv.cvtColor(img, img, cv.COLOR_GRAY2RGBA);
			break;
		case cv.CV_8UC3:
			cv.cvtColor(img, img, cv.COLOR_RGB2RGBA);
			break;
		case cv.CV_8UC4:
			break;
		default:
			throw new Error("Bad number of channels (Source image must have 1, 3 or 4 channels)");
	}
	const clampedArray = new ImageData(new Uint8ClampedArray(img.data), img.cols, img.rows);
	return clampedArray;
}

/**
 * This exists to capture all the events that are thrown out of the worker
 * into the worker. Without this, there would be no communication possible
 * with the project.
 */
onmessage = async function (e) {
	switch (e.data.msg) {
		case "load": {
			try {
				// load opencv depending on wasm features available
				self.importScripts(paths.openCvWasmFeatureDetect);
				const opencvScript = await getOpenCV();
				self.importScripts(opencvScript);
				cv = await cv;

				// load tensorflow scripts
				self.importScripts(paths.tfjs);
				self.importScripts(paths.tfjsWasmBackend);
				tf.wasm.setWasmPaths({
					"tfjs-backend-wasm.wasm": paths.tfjsWasm,
					"tfjs-backend-wasm-simd.wasm": paths.tfjsWasmSimd,
					"tfjs-backend-wasm-threaded-simd.wasm": paths.tfjsWasmThreadedSimd
				});
				tf.setBackend("wasm");
				await tf.ready();
			} catch (err) {
				throw new Error(err);
			}

			postMessage({ msg: e.data.msg });
			break;
		}
		case "imageProcessing":
			return imageProcessing(e.data);
		default:
			break;
	}
};
